
<!DOCTYPE html>
<html>
  <head>
    <title>Redet</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      /* Slideshow styles */
    </style>
    <!-- MathJax support  -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        showProcessingMessages: false,
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- MathJax support end -->
  </head>
  <body>
<textarea id="source">

## How to use Redet

## 1. Login

IP shall be under the Campus Local Area Network

```sh
ssh redet@10.15.3.46
```

<!--  -->
---
<!--  -->


## 2. conda activate 

Activate conda redet

```conda
conda activate redet
```

<!--  -->
---
<!--  -->

## 3. torch version

The torch version is 1.8.1

```sh
$ python
Python 3.7.16 (default, Jan 17 2023, 22:20:44)
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> torch.__version__
'1.8.1+cu111'
>>> torch.cuda.is_available()
True
>>>
```

<!--  -->
---
<!--  -->

## 4. Change directory to ReDet

```sh
cd Torch/ReDet/
```

output

```sh
(redet) redet@super6-B650M-DS3H:~/Torch/ReDet$ ls
compile.sh  data  demo_large_image.py  DOTA_devkit         INSTALL.md  mmdet           network.png  requirements.txt  TECHNICAL_DETAILS.md  work_dirs
configs     demo  docs                 GETTING_STARTED.md  LICENSE     mmdet.egg-info  README.md    setup.py          tools
```

<!--  -->
---
<!--  -->


## 5. Train

Train example code 
```sh
 python tools/train.py configs/ReDet/ReDet_re50_refpn_1x_dota15.py
```


Train Redet

> Ignorance of the mismatch, which are not effect to the epoch generation

>ref: https://github.com/csuhan/ReDet/issues/12

> the ReDet Repo Owner, 
csuhan: It is normal and will not affect the inference.
The key filter in state_dicts is automatically generated by the equivariant networks (backbone), so we do not incldue this keys in pretrained models.


<!--  -->
---
<!--  -->

```sh
(redet) redet@super6-B650M-DS3H:~/Torch/ReDet$ python tools/train.py configs/ReDet/ReDet_re50_refpn_1x_dota15.py
2023-11-03 12:32:03,019 - INFO - Distributed training: False
/home/redet/miniconda3/envs/redet/lib/python3.7/site-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  full_mask[mask] = norms.to(torch.uint8)
2023-11-03 12:32:14,101 - INFO - load model from: work_dirs/ReResNet_pretrain/re_resnet50_c8_batch256-12933bc2.pth
2023-11-03 12:32:14,109 - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: head.fc.weight, head.fc.bias

missing keys in source state_dict: layer3.4.conv2.filter, layer4.0.conv1.filter, layer1.0.conv2.filter, layer1.2.conv3.filter, layer3.4.conv1.filter, layer4.2.conv3.filter, layer2.1.conv2.filter, layer1.0.conv3.filter, layer4.0.downsample.0.filter, layer2.2.conv1.filter, layer2.0.conv2.filter, layer4.2.conv2.filter, layer2.0.conv1.filter, layer4.0.conv2.filter, layer4.1.conv3.filter, layer3.3.conv2.filter, layer2.3.conv1.filter, layer1.0.conv1.filter, layer3.3.conv3.filter, layer3.5.conv3.filter, layer3.1.conv2.filter, layer4.2.conv1.filter, layer3.5.conv2.filter, layer2.1.conv1.filter, layer1.0.downsample.0.filter, layer2.2.conv2.filter, layer3.5.conv1.filter, layer2.0.downsample.0.filter, layer4.0.conv3.filter, layer3.2.conv3.filter, layer3.0.conv3.filter, layer2.2.conv3.filter, layer1.1.conv2.filter, layer3.2.conv2.filter, layer2.3.conv2.filter, layer3.2.conv1.filter, layer3.0.downsample.0.filter, layer4.1.conv1.filter, layer3.1.conv1.filter, layer1.1.conv3.filter, layer4.1.conv2.filter, layer1.2.conv2.filter, layer3.1.conv3.filter, layer1.1.conv1.filter, layer2.3.conv3.filter, layer2.0.conv3.filter, layer3.4.conv3.filter, layer3.0.conv2.filter, layer2.1.conv3.filter, layer3.3.conv1.filter, layer1.2.conv1.filter, conv1.filter, layer3.0.conv1.filter

loading annotations into memory...
Done (t=2.17s)
creating index...
index created!
2023-11-03 12:32:18,820 - INFO - Start running, host: redet@super6-B650M-DS3H, work_dir: /home/redet/Torch/ReDet/work_dirs/ReDet_re50_refpn_1x_dota15
2023-11-03 12:32:18,820 - INFO - workflow: [('train', 1)], max: 12 epochs
/home/redet/Torch/ReDet/mmdet/core/anchor/anchor_target.py:112: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  anchors = flat_anchors[inside_flags, :]
/home/redet/Torch/ReDet/mmdet/core/anchor/anchor_target.py:185: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  ret[inds] = data
/home/redet/Torch/ReDet/mmdet/core/anchor/anchor_target.py:189: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  ret[inds, :] = data
/home/redet/Torch/ReDet/mmdet/core/bbox/transforms.py:56: UserWarning: This overload of addcmul is deprecated:
        addcmul(Tensor input, Number value, Tensor tensor1, Tensor tensor2, *, Tensor out)
Consider using one of the following signatures instead:
        addcmul(Tensor input, Tensor tensor1, Tensor tensor2, *, Number value, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)
  gx = torch.addcmul(px, 1, pw, dx)  # gx = px + pw * dx
/home/redet/Torch/ReDet/mmdet/models/rbbox_heads/rbbox_head.py:314: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)
  bboxes_list.append(bboxes[keep_inds])
2023-11-03 12:33:03,511 - INFO - Epoch [1][50/7260]     lr: 0.00399, eta: 21:29:37, time: 0.889, data_time: 0.128, memory: 5800, loss_rpn_cls: 0.4930, loss_rpn_bbox: 0.1228, s0.rbbox_loss_cls: 0.5461, s0.rbbox_acc: 90.7285, s0.rbbox_loss_bbox: 0.4393, s1.rbbox_loss_cls: 0.4526, s1.rbbox_acc: 92.4283, s1.rbbox_loss_bbox: 0.0817, loss: 2.1355
```


<!--  -->
---
<!--  -->


The Epoch of Redet shall be like this



```sh
2023-11-03 12:33:03,511 - INFO - Epoch [1][50/7260]     lr: 0.00399, eta: 21:29:37, time: 0.889, data_time: 0.128, memory: 5800, loss_rpn_cls: 0.4930, loss_rpn_bbox: 0.1228, s0.rbbox_loss_cls: 0.5461, s0.rbbox_acc: 90.7285, s0.rbbox_loss_bbox: 0.4393, s1.rbbox_loss_cls: 0.4526, s1.rbbox_acc: 92.4283, s1.rbbox_loss_bbox: 0.0817, loss: 2.1355
2023-11-03 12:33:38,971 - INFO - Epoch [1][100/7260]    lr: 0.00465, eta: 19:18:46, time: 0.709, data_time: 0.047, memory: 5800, loss_rpn_cls: 0.2873, loss_rpn_bbox: 0.0952, s0.rbbox_loss_cls: 0.4344, s0.rbbox_acc: 91.3613, s0.rbbox_loss_bbox: 0.4885, s1.rbbox_loss_cls: 0.2908, s1.rbbox_acc: 94.3583, s1.rbbox_loss_bbox: 0.2014, loss: 1.7974
2023-11-03 12:34:19,711 - INFO - Epoch [1][150/7260]    lr: 0.00532, eta: 19:25:45, time: 0.815, data_time: 0.095, memory: 5800, loss_rpn_cls: 0.3094, loss_rpn_bbox: 0.1077, s0.rbbox_loss_cls: 0.5346, s0.rbbox_acc: 88.6152, s0.rbbox_loss_bbox: 0.5817, s1.rbbox_loss_cls: 0.3879, s1.rbbox_acc: 91.6497, s1.rbbox_loss_bbox: 0.2355, loss: 2.1569
2023-11-03 12:35:01,170 - INFO - Epoch [1][200/7260]    lr: 0.00599, eta: 19:34:06, time: 0.829, data_time: 0.071, memory: 5800, loss_rpn_cls: 0.2239, loss_rpn_bbox: 0.1054, s0.rbbox_loss_cls: 0.5205, s0.rbbox_acc: 88.5918, s0.rbbox_loss_bbox: 0.5066, s1.rbbox_loss_cls: 0.4100, s1.rbbox_acc: 90.6026, s1.rbbox_loss_bbox: 0.3745, loss: 2.1408
2023-11-03 12:35:44,329 - INFO - Epoch [1][250/7260]    lr: 0.00665, eta: 19:48:38, time: 0.863, data_time: 0.073, memory: 5800, loss_rpn_cls: 0.1942, loss_rpn_bbox: 0.0948, s0.rbbox_loss_cls: 0.5406, s0.rbbox_acc: 87.6523, s0.rbbox_loss_bbox: 0.5291, s1.rbbox_loss_cls: 0.3972, s1.rbbox_acc: 90.3339, s1.rbbox_loss_bbox: 0.4407, loss: 2.1965
2023-11-03 12:36:27,110 - INFO - Epoch [1][300/7260]    lr: 0.00732, eta: 19:56:20, time: 0.856, data_time: 0.084, memory: 5800, loss_rpn_cls: 0.2314, loss_rpn_bbox: 0.1064, s0.rbbox_loss_cls: 0.5227, s0.rbbox_acc: 87.3770, s0.rbbox_loss_bbox: 0.4589, s1.rbbox_loss_cls: 0.4190, s1.rbbox_acc: 89.8363, s1.rbbox_loss_bbox: 0.4143, loss: 2.1525
2023-11-03 12:37:09,011 - INFO - Epoch [1][350/7260]    lr: 0.00799, eta: 19:57:59, time: 0.838, data_time: 0.070, memory: 5800, loss_rpn_cls: 0.1731, loss_rpn_bbox: 0.0976, s0.rbbox_loss_cls: 0.4558, s0.rbbox_acc: 88.8516, s0.rbbox_loss_bbox: 0.4244, s1.rbbox_loss_cls: 0.3701, s1.rbbox_acc: 90.7472, s1.rbbox_loss_bbox: 0.4366, loss: 1.9577
2023-11-03 12:37:49,944 - INFO - Epoch [1][400/7260]    lr: 0.00865, eta: 19:55:32, time: 0.819, data_time: 0.063, memory: 5800, loss_rpn_cls: 0.1806, loss_rpn_bbox: 0.0867, s0.rbbox_loss_cls: 0.4761, s0.rbbox_acc: 87.5254, s0.rbbox_loss_bbox: 0.5364, s1.rbbox_loss_cls: 0.3642, s1.rbbox_acc: 89.9981, s1.rbbox_loss_bbox: 0.5080, loss: 2.1520
2023-11-03 12:38:31,804 - INFO - Epoch [1][450/7260]    lr: 0.00932, eta: 19:56:27, time: 0.837, data_time: 0.073, memory: 5800, loss_rpn_cls: 0.1668, loss_rpn_bbox: 0.0919, s0.rbbox_loss_cls: 0.5685, s0.rbbox_acc: 86.2832, s0.rbbox_loss_bbox: 0.6825, s1.rbbox_loss_cls: 0.3852, s1.rbbox_acc: 89.5976, s1.rbbox_loss_bbox: 0.5760, loss: 2.4708
2023-11-03 12:39:12,102 - INFO - Epoch [1][500/7260]    lr: 0.00999, eta: 19:52:32, time: 0.806, data_time: 0.063, memory: 5800, loss_rpn_cls: 0.1441, loss_rpn_bbox: 0.0866, s0.rbbox_loss_cls: 0.4604, s0.rbbox_acc: 88.2207, s0.rbbox_loss_bbox: 0.4981, s1.rbbox_loss_cls: 0.3332, s1.rbbox_acc: 90.9321, s1.rbbox_loss_bbox: 0.4650, loss: 1.9874
2023-11-03 12:39:57,781 - INFO - Epoch [1][550/7260]    lr: 0.01000, eta: 20:03:20, time: 0.914, data_time: 0.126, memory: 5800, loss_rpn_cls: 0.1727, loss_rpn_bbox: 0.1301, s0.rbbox_loss_cls: 0.5019, s0.rbbox_acc: 85.5586, s0.rbbox_loss_bbox: 0.5222, s1.rbbox_loss_cls: 0.3563, s1.rbbox_acc: 89.4112, s1.rbbox_loss_bbox: 0.5068, loss: 2.1900
2023-11-03 12:40:38,394 - INFO - Epoch [1][600/7260]    lr: 0.01000, eta: 20:00:01, time: 0.812, data_time: 0.068, memory: 5800, loss_rpn_cls: 0.1568, loss_rpn_bbox: 0.0970, s0.rbbox_loss_cls: 0.3941, s0.rbbox_acc: 89.5645, s0.rbbox_loss_bbox: 0.4318, s1.rbbox_loss_cls: 0.3255, s1.rbbox_acc: 91.3245, s1.rbbox_loss_bbox: 0.4171, loss: 1.8223
2023-11-03 12:41:20,589 - INFO - Epoch [1][650/7260]    lr: 0.01000, eta: 20:00:37, time: 0.844, data_time: 0.081, memory: 5800, loss_rpn_cls: 0.1481, loss_rpn_bbox: 0.0916, s0.rbbox_loss_cls: 0.4268, s0.rbbox_acc: 87.8652, s0.rbbox_loss_bbox: 0.4908, s1.rbbox_loss_cls: 0.3338, s1.rbbox_acc: 90.1052, s1.rbbox_loss_bbox: 0.5118, loss: 2.0028
2023-11-03 12:42:02,391 - INFO - Epoch [1][700/7260]    lr: 0.01000, eta: 20:00:14, time: 0.836, data_time: 0.073, memory: 5800, loss_rpn_cls: 0.1370, loss_rpn_bbox: 0.0931, s0.rbbox_loss_cls: 0.4624, s0.rbbox_acc: 86.5039, s0.rbbox_loss_bbox: 0.5225, s1.rbbox_loss_cls: 0.3469, s1.rbbox_acc: 89.8299, s1.rbbox_loss_bbox: 0.5761, loss: 2.1379
2023-11-03 12:42:43,537 - INFO - Epoch [1][750/7260]    lr: 0.01000, eta: 19:58:32, time: 0.823, data_time: 0.067, memory: 5800, loss_rpn_cls: 0.1212, loss_rpn_bbox: 0.0868, s0.rbbox_loss_cls: 0.4085, s0.rbbox_acc: 88.8770, s0.rbbox_loss_bbox: 0.4338, s1.rbbox_loss_cls: 0.3346, s1.rbbox_acc: 90.5601, s1.rbbox_loss_bbox: 0.5226, loss: 1.9076
2023-11-03 12:43:30,859 - INFO - Epoch [1][800/7260]    lr: 0.01000, eta: 20:08:05, time: 0.946, data_time: 0.147, memory: 5800, loss_rpn_cls: 0.1433, loss_rpn_bbox: 0.0933, s0.rbbox_loss_cls: 0.4642, s0.rbbox_acc: 86.4082, s0.rbbox_loss_bbox: 0.4624, s1.rbbox_loss_cls: 0.3748, s1.rbbox_acc: 89.2309, s1.rbbox_loss_bbox: 0.5453, loss: 2.0833
2023-11-03 12:44:11,527 - INFO - Epoch [1][850/7260]    lr: 0.01000, eta: 20:05:09, time: 0.813, data_time: 0.067, memory: 5800, loss_rpn_cls: 0.1242, loss_rpn_bbox: 0.0773, s0.rbbox_loss_cls: 0.4273, s0.rbbox_acc: 88.0254, s0.rbbox_loss_bbox: 0.4755, s1.rbbox_loss_cls: 0.3518, s1.rbbox_acc: 89.8915, s1.rbbox_loss_bbox: 0.5321, loss: 1.9881
2023-11-03 12:44:56,037 - INFO - Epoch [1][900/7260]    lr: 0.01000, eta: 20:08:36, time: 0.890, data_time: 0.115, memory: 5800, loss_rpn_cls: 0.1482, loss_rpn_bbox: 0.0833, s0.rbbox_loss_cls: 0.4152, s0.rbbox_acc: 88.2148, s0.rbbox_loss_bbox: 0.5131, s1.rbbox_loss_cls: 0.3478, s1.rbbox_acc: 90.0385, s1.rbbox_loss_bbox: 0.5006, loss: 2.0081
2023-11-03 12:45:41,526 - INFO - Epoch [1][950/7260]    lr: 0.01000, eta: 20:13:06, time: 0.910, data_time: 0.119, memory: 5800, loss_rpn_cls: 0.1366, loss_rpn_bbox: 0.0846, s0.rbbox_loss_cls: 0.4239, s0.rbbox_acc: 87.7871, s0.rbbox_loss_bbox: 0.5363, s1.rbbox_loss_cls: 0.3346, s1.rbbox_acc: 90.6918, s1.rbbox_loss_bbox: 0.4724, loss: 1.9884
2023-11-03 12:46:18,346 - INFO - Epoch [1][1000/7260]   lr: 0.01000, eta: 20:04:37, time: 0.736, data_time: 0.045, memory: 5800, loss_rpn_cls: 0.1110, loss_rpn_bbox: 0.0842, s0.rbbox_loss_cls: 0.3673, s0.rbbox_acc: 89.7480, s0.rbbox_loss_bbox: 0.5102, s1.rbbox_loss_cls: 0.2810, s1.rbbox_acc: 91.9225, s1.rbbox_loss_bbox: 0.4635, loss: 1.8172
2023-11-03 12:46:53,848 - INFO - Epoch [1][1050/7260]   lr: 0.01000, eta: 19:55:06, time: 0.710, data_time: 0.052, memory: 5800, loss_rpn_cls: 0.1025, loss_rpn_bbox: 0.0780, s0.rbbox_loss_cls: 0.3746, s0.rbbox_acc: 88.9590, s0.rbbox_loss_bbox: 0.4415, s1.rbbox_loss_cls: 0.2895, s1.rbbox_acc: 91.2423, s1.rbbox_loss_bbox: 0.4991, loss: 1.7853
2023-11-03 12:47:33,727 - INFO - Epoch [1][1100/7260]   lr: 0.01000, eta: 19:52:05, time: 0.798, data_time: 0.060, memory: 5800, loss_rpn_cls: 0.1007, loss_rpn_bbox: 0.0808, s0.rbbox_loss_cls: 0.3434, s0.rbbox_acc: 90.3027, s0.rbbox_loss_bbox: 0.3672, s1.rbbox_loss_cls: 0.2711, s1.rbbox_acc: 92.2888, s1.rbbox_loss_bbox: 0.3776, loss: 1.5409
```


</textarea> 
<!-- <script src="https://remarkjs.com/downloads/remark-0.6.3.min.js" type="text/javascript"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js" type="text/javascript"></script>
<!-- Uncomment this if there is no internet -->
<!-- <script src="remark-0.6.3.min.js" type="text/javascript"> -->
<!--   </script> -->

<script type="text/javascript">
  var slideshow = remark.create(      {
    // Navigation options
    navigation: {
      // Enable or disable navigating using scroll
      // Default: true
      // Alternatives: false
      scroll: false,
    }
  }
  );
</script>
</body>
</html>